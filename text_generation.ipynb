{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 1. Install and Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-21T20:47:08.859713Z","iopub.status.busy":"2024-10-21T20:47:08.859438Z","iopub.status.idle":"2024-10-21T20:47:21.579292Z","shell.execute_reply":"2024-10-21T20:47:21.578349Z","shell.execute_reply.started":"2024-10-21T20:47:08.859680Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"]}],"source":["!pip install datasets transformers\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:45:28.396440Z","iopub.status.busy":"2024-10-21T20:45:28.396094Z","iopub.status.idle":"2024-10-21T20:45:31.281984Z","shell.execute_reply":"2024-10-21T20:45:31.281005Z","shell.execute_reply.started":"2024-10-21T20:45:28.396403Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n","0 upgraded, 0 newly installed, 0 to remove and 68 not upgraded.\n"]}],"source":["!apt install git-lfs\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:47:21.581418Z","iopub.status.busy":"2024-10-21T20:47:21.581096Z","iopub.status.idle":"2024-10-21T20:47:36.885797Z","shell.execute_reply":"2024-10-21T20:47:36.884825Z","shell.execute_reply.started":"2024-10-21T20:47:21.581383Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting arabert\n","  Downloading arabert-1.0.1-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: PyArabic in /opt/conda/lib/python3.10/site-packages (from arabert) (0.6.15)\n","Collecting farasapy (from arabert)\n","  Downloading farasapy-0.0.14-py3-none-any.whl.metadata (8.9 kB)\n","Collecting emoji==1.4.2 (from arabert)\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from farasapy->arabert) (2.32.3)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from farasapy->arabert) (4.66.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from PyArabic->arabert) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->farasapy->arabert) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->farasapy->arabert) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->farasapy->arabert) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->farasapy->arabert) (2024.8.30)\n","Downloading arabert-1.0.1-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n","Building wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186459 sha256=d8830ff6c3b9367c30f71b45418b1aa4d112f8ccb4efdcc5d955411bb8313d96\n","  Stored in directory: /root/.cache/pip/wheels/10/f0/fd/4813b1177405693e8da9cdea839f0fb64fde161380e058c827\n","Successfully built emoji\n","Installing collected packages: emoji, farasapy, arabert\n","  Attempting uninstall: emoji\n","    Found existing installation: emoji 2.13.2\n","    Uninstalling emoji-2.13.2:\n","      Successfully uninstalled emoji-2.13.2\n","Successfully installed arabert-1.0.1 emoji-1.4.2 farasapy-0.0.14\n"]}],"source":["!pip install arabert"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:47:36.887698Z","iopub.status.busy":"2024-10-21T20:47:36.887401Z","iopub.status.idle":"2024-10-21T20:47:57.409194Z","shell.execute_reply":"2024-10-21T20:47:57.408201Z","shell.execute_reply.started":"2024-10-21T20:47:36.887665Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4.45.1\n"]}],"source":["import transformers\n","print(transformers.__version__)\n","from datasets import ClassLabel\n","import random\n","import pandas as pd\n","from IPython.display import display, HTML\n","from arabert.preprocess import ArabertPreprocessor\n","from transformers import GPT2TokenizerFast, GPT2LMHeadModel, Trainer, TrainingArguments, pipeline\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from datasets import load_dataset, Dataset, DatasetDict\n","from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n","from transformers import GPT2TokenizerFast, pipeline\n","from transformers import DataCollatorForLanguageModeling\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import math\n"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Login to HuggingFace \n","login to save save the model online"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:48:04.837312Z","iopub.status.busy":"2024-10-21T20:48:04.836566Z","iopub.status.idle":"2024-10-21T20:48:04.863338Z","shell.execute_reply":"2024-10-21T20:48:04.862483Z","shell.execute_reply.started":"2024-10-21T20:48:04.837271Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b0fd6dcc15d40e78ce8cd23c26b4802","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","notebook_login()\n","# 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"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Load and Proccess the Dataset\n","* Load private dataset from kalimat that has been combine all categories text in one CSV file.\n","* Preprocesses the text using the ArabertPreprocessor. \n","* Splits the data into training(80%) and testing(20%) sets \n","* converts them into the Hugging Face Dataset format, and organizes them into a DatasetDict for further use in model training and evaluation.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:48:14.292478Z","iopub.status.busy":"2024-10-21T20:48:14.292078Z","iopub.status.idle":"2024-10-21T20:50:00.872952Z","shell.execute_reply":"2024-10-21T20:50:00.872148Z","shell.execute_reply.started":"2024-10-21T20:48:14.292438Z"},"trusted":true},"outputs":[],"source":["# Load  Arabic CSV file \n","\n","file_path = \"/kaggle/input/gennnn/output_gen.csv\"\n","df = pd.read_csv(file_path)\n","\n","# Initialize preprocessor and model\n","arabert_prep = ArabertPreprocessor(model_name='aubmindlab/aragpt2-base')\n","\n","# Preprocess the articles\n","df['text'] = df['text'].apply(arabert_prep.preprocess)\n","\n","# Split the dataset into train and test sets\n","train_texts, test_texts = train_test_split(df['text'], test_size=0.1)\n","\n","# Convert the texts into Hugging Face Dataset format\n","train_dataset = Dataset.from_pandas(pd.DataFrame(train_texts, columns=[\"text\"]))\n","test_dataset = Dataset.from_pandas(pd.DataFrame(test_texts, columns=[\"text\"]))\n","\n","train_dataset = train_dataset.remove_columns(['__index_level_0__'])\n","test_dataset = test_dataset.remove_columns(['__index_level_0__'])\n","\n","# Combine datasets into a DatasetDict\n","datasets = DatasetDict({\n","    'train': train_dataset,\n","    'test': test_dataset\n","})\n"]},{"cell_type":"markdown","metadata":{},"source":["* Show the dataset structure "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:50:00.874794Z","iopub.status.busy":"2024-10-21T20:50:00.874488Z","iopub.status.idle":"2024-10-21T20:50:00.881712Z","shell.execute_reply":"2024-10-21T20:50:00.880810Z","shell.execute_reply.started":"2024-10-21T20:50:00.874761Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text'],\n","        num_rows: 16383\n","    })\n","    test: Dataset({\n","        features: ['text'],\n","        num_rows: 1821\n","    })\n","})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["datasets"]},{"cell_type":"markdown","metadata":{},"source":["* This method randomly selects and displays a specified number or just 3 of unique examples from the dataset and showing the results in an HTML table format."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:50:00.883191Z","iopub.status.busy":"2024-10-21T20:50:00.882825Z","iopub.status.idle":"2024-10-21T20:50:00.893668Z","shell.execute_reply":"2024-10-21T20:50:00.892963Z","shell.execute_reply.started":"2024-10-21T20:50:00.883160Z"},"trusted":true},"outputs":[],"source":["def show_random_elements(dataset, num_examples=3):\n","    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n","    picks = []\n","    for _ in range(num_examples):\n","        pick = random.randint(0, len(dataset)-1)\n","        while pick in picks:\n","            pick = random.randint(0, len(dataset)-1)\n","        picks.append(pick)\n","    \n","    df = pd.DataFrame(dataset[picks])\n","    for column, typ in dataset.features.items():\n","        if isinstance(typ, ClassLabel):\n","            df[column] = df[column].transform(lambda i: typ.names[i])\n","    display(HTML(df.to_html()))"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:50:00.895977Z","iopub.status.busy":"2024-10-21T20:50:00.895646Z","iopub.status.idle":"2024-10-21T20:50:00.916095Z","shell.execute_reply":"2024-10-21T20:50:00.915250Z","shell.execute_reply.started":"2024-10-21T20:50:00.895944Z"},"trusted":true},"outputs":[{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ÙŠØ·Ø¹Ù… ÙƒÙ„ Ø­Ø§Ø¬ Ø¨Ø¬Ø±Ø¹Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø·Ø¹Ù… Ø§Ù„Ø­Ù…Ù‰ Ø§Ù„Ù…Ø®ÙŠØ© Ø§Ù„Ø´ÙˆÙƒÙŠØ© ( Ø§Ù„Ø·Ø¹Ù… Ø§Ù„Ø±Ø¨Ø§Ø¹ÙŠ ) Ù‚Ø¨Ù„ Ø§Ù„Ø³ÙØ± Ø¨Ø¹Ø´Ø±Ø© Ø£ÙŠØ§Ù… ÙˆØ°Ù„Ùƒ Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù…Ù†Ø§Ø¹Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø³ÙØ± ÙˆÙ„Ø­Ù…Ø§ÙŠØªÙ‡ Ù…Ù† Ø§Ù„Ø¥ØµØ§Ø¨Ø© Ø¨Ø§Ù„Ù…Ø±Ø¶ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆØ§Ø¬Ø¯Ù‡ ÙÙŠ Ø§Ù„Ø¯ÙŠØ§Ø± Ø§Ù„Ù…Ù‚Ø¯Ø³Ø© Ø­ÙŠØ« Ø£Ù† Ø§Ù„ØªØ·Ø¹ÙŠÙ… Ø¨Ù‡Ø°Ø§ Ø§Ù„Ù„Ù‚Ø§Ø­ Ø¶Ø±ÙˆØ±ÙŠ Ø¬Ø¯Ø§ Ø­ÙŠØ« Ø£Ù† Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø¥ØµØ§Ø¨Ø© Ø¨Ø§Ù„Ù…Ø±Ø¶ Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„ÙØªØ±Ø© Ù„ØªÙˆØ§ÙØ± Ø¨Ø¹Ø¶ Ø§Ù„Ø¸Ø±ÙˆÙ Ø§Ù„ØªÙŠ ØªØ³Ø§Ø¹Ø¯ ÙˆØªØ²ÙŠØ¯ Ù…Ù† ÙØ±Øµ Ø§Ù„Ø¥ØµØ§Ø¨Ø© Ù„Ù„Ø£Ø´Ø®Ø§Øµ Ø§Ù„ØºÙŠØ± Ù…Ø·Ø¹Ù…ÙŠÙ† Ø­ÙŠØ« Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ø±Ø¶ ÙŠÙ†ØªÙ‚Ù„ Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„ØªÙ†ÙØ³ÙŠ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ø±Ø°Ø§Ø° Ø§Ù„Ù…ØªØ·Ø§ÙŠØ± Ù…Ù† Ø§Ù„Ù…Ø±ÙŠØ¶ Ø£Ùˆ Ø­Ø§Ù…Ù„ Ø§Ù„Ù…Ø±Ø¶ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¹Ø·Ø³ Ø£Ùˆ Ø§Ù„Ø³Ø¹Ø§Ù„ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ù„ÙˆØ«Ø© Ø¨Ø§Ù„Ù…ÙŠÙƒØ±ÙˆØ¨ . ÙƒÙ…Ø§ Ø£Ù† Ù…Ø¯Ø© Ù‡Ø°Ø§ Ø§Ù„Ø·Ø¹Ù… Ù‡Ùˆ Ø«Ù„Ø§Ø« Ø³Ù†ÙˆØ§Øª ÙÙ„Ø°Ù„Ùƒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¶Ø±ÙˆØ±Ø© Ù„Ø£Ø®Ø° Ø§Ù„Ø·Ø¹Ù… Ù„Ù…Ù† Ø·Ø¹Ù… Ø¨Ù‡ ÙÙŠ Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø«Ù„Ø§Ø« Ø§Ù„Ù…Ø§Ø¶ÙŠØ© ÙˆÙ„ÙƒÙ† ÙŠÙ†Ø¨ØºÙŠ ØªØ³Ø¬ÙŠÙ„ ØªØ§Ø±ÙŠØ® Ø§Ø®Ø° Ø§Ù„Ø·Ø¹Ù… ÙƒØ°Ù„Ùƒ ÙÙŠ Ø§Ù„Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„ØµØ­ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù† Ø§Ù„Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø§Ù„Ù…Ø¹Ø·Ø§Ø© Ø³Ø§Ø¨Ù‚Ø§ Ù„Ù…Ù† ÙŠØ­ØªÙØ¸ Ø¨Ù‡Ø§ Ø£Ùˆ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„ØµØ­ÙŠ Ø§Ù„Ø°ÙŠ Ù‚Ø¯ ØªØ·Ø¹Ù… Ø¨Ù‡ Ø­ÙŠØ« ÙŠØªÙ… Ø§Ø®Ø° Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø§Ù„Ù…Ø¤Ø³Ø³Ø© Ø§Ù„ØµØ­ÙŠØ© ÙˆÙ…Ù† Ø§Ù„Ø¬Ø¯ÙŠØ± Ø¨Ø§Ù„Ø°ÙƒØ± Ø§Ù†Ù‡ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙˆØ§Ù†Ø¹ Ù„Ø£Ø®Ø° Ù‡Ø°Ø§ Ø§Ù„Ø·Ø¹Ù… Ø£Ùˆ Ø£ÙŠØ© Ù…Ø¶Ø§Ø¹ÙØ§Øª Ù„Ù‡ ÙˆÙ„Ø°Ø§ ÙÙ„Ø§ ÙŠÙ†Ø¨ØºÙŠ Ø§Ù„ØªØ®ÙˆÙ Ù…Ù† Ø£Ø®Ø°Ù‡ ÙˆÙ‚Ø¯ ÙŠÙ‚ÙˆÙ„ Ù‚Ø§Ø¦Ù„ Ù„Ù‚Ø¯ Ø°Ù‡Ø¨Ù†Ø§ ÙˆÙ„Ù… Ù†ØµØ¨ Ø¨Ø£ÙŠ Ù…Ø±Ø¶ ÙˆÙ„ÙƒÙ† Ù‡Ù„ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø© ØªØ³Ù„Ù… Ø§Ù„Ø¬Ø±Ø© ÙÙ„Ù…Ø§Ø°Ø§ Ù„Ø§ ØªÙƒÙˆÙ† Ø§Ù„ÙˆÙ‚Ø§ÙŠØ© Ø®ÙŠØ± Ù…Ù† Ø§Ù„Ø¹Ù„Ø§Ø¬ .</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ØºØ²Ø© Ø§Ù„ÙˆØ·Ù† : Ø¹Ø±Ø¶ Ù…Ø¤Ø®Ø±Ø§ ÙÙŠÙ„Ù… ( Ù†Ø³Ø§Ø¡ ÙÙŠ Ø§Ù„ØµØ±Ø§Ø¹ ) Ù„Ù„Ù…Ø®Ø±Ø¬Ø© Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠØ© Ø¨Ø«ÙŠÙ†Ø© ÙƒÙ†Ø¹Ø§Ù† Ø§Ù„Ø®ÙˆØ±ÙŠ Ø¹Ù„Ù‰ Ø´Ø§Ø´Ø© Ø³ÙŠÙ†Ù…Ø§ØªÙƒ ÙˆÙ…Ø³Ø±Ø­ Ø§Ù„Ù‚ØµØ¨Ø© ÙÙŠ Ø±Ø§Ù… Ø§Ù„Ù„Ù‡ ÙÙŠ Ø§Ù„Ø¶ÙØ© Ø§Ù„ØºØ±Ø¨ÙŠØ© . ÙˆØªÙ†Ø§ÙˆÙ„ Ø§Ù„ÙÙŠÙ„Ù… Ø¹Ù„Ù‰ Ù…Ø¯Ù‰ Ø³Ø§Ø¹Ø© Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„ÙƒÙØ§Ø­ÙŠØ© Ø§Ù„Ø¹Ø±ÙŠÙ‚Ø© Ù„Ù„Ù…Ø±Ø£Ø© Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠØ© ÙˆÙ…Ø´Ø§Ø±ÙƒØªÙ‡Ø§ Ø§Ù„ÙØ§Ø¹Ù„Ø© ÙÙŠ Ø§Ù„Ù…Ø¹ØªØ±Ùƒ Ø§Ù„Ù†Ø¶Ø§Ù„ÙŠ Ø§Ù„ØªØ­Ø±Ø±ÙŠ Ù…Ù† Ø£ÙˆØ³Ø¹ Ø£Ø¨ÙˆØ§Ø¨Ù‡ ÙˆÙ…Ø®ØªÙ„Ù Ø®Ù†Ø§Ø¯Ù‚Ù‡ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ø¨Ø§Ø³ØªÙ„Ù‡Ø§Ù… ÙˆØªÙˆØ«ÙŠÙ‚ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø£Ø³ÙŠØ±Ø§Øª ÙƒØ¥Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¯Ø®Ù„ . ÙˆÙŠØªÙ…ÙŠØ² Ø§Ù„ÙÙŠÙ„Ù… Ø§Ù„Ø°ÙŠ Ø¹Ø±Ø¶ Ø¨Ø±Ø¹Ø§ÙŠØ© ÙˆØ²Ø§Ø±Ø© Ø´Ø¤ÙˆÙ† Ø§Ù„Ø£Ø³Ø±Ù‰ ÙˆØ§Ù„Ù…Ø­Ø±Ø±ÙŠÙ† ÙˆÙ…Ø­Ø§ÙØ¸Ø© Ø±Ø§Ù… Ø§Ù„Ù„Ù‡ ÙˆØ§Ù„Ø¨ÙŠØ±Ø© ÙˆØ¨ØªÙ†Ø³ÙŠÙ‚ Ù…Ø¹ Ø§ØªØ­Ø§Ø¯ Ù„Ø¬Ø§Ù† Ø§Ù„Ù…Ø±Ø£Ø© Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ Ø¨Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø§Øª ÙˆØ§Ù„Ø£Ø³Ø¨Ø§Ø¨ ÙˆØ§Ù„Ø¯ÙˆØ§ÙØ¹ ÙˆØ±Ø§Ø¡ Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ø±Ø£Ø© Ù‡Ø°Ø§ Ø§Ù„Ù…ÙŠØ¯Ø§Ù† Ø§Ù„ØµØ¹Ø¨ ÙˆØ§Ù„Ù…Ø´Ø±Ù ÙˆØ§Ù†Ø¹ÙƒØ§Ø³Ø§ØªÙ‡ ÙˆØªØ¨Ø¹Ø§ØªÙ‡ ÙˆØ¥Ø±Ù‡Ø§ØµØ§ØªÙ‡ Ø¨ÙƒÙ„ Ø£Ø¨Ø¹Ø§Ø¯Ù‡Ø§ Ø§Ù„Ù…ØªØ±Ø§ÙÙ‚Ø© ÙˆØ§Ù„Ù„Ø§Ø­Ù‚Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø§Ø¶Ù„Ø© Ø®ØµÙˆØµØ§ ÙˆØ§Ù„Ø­Ø±ÙƒØ© Ø§Ù„Ù†Ø³ÙˆÙŠØ© Ø¹Ù…ÙˆÙ…Ø§ . ÙˆÙŠØªØ¹Ø±Ø¶ Ø§Ù„ÙÙŠÙ„Ù… Ù„ØªØ¬Ø±Ø¨Ø© Ø£Ø±Ø¨Ø¹ Ø£Ø³ÙŠØ±Ø§Øª Ù…Ø­Ø±Ø±Ø§Øª Ø¹Ø§ÙŠØ´Ù† Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù†Ø¶Ø§Ù„ÙŠØ© ÙˆÙ…Ù† Ø«Ù… Ø§Ù„ØªÙˆÙ‚ÙŠÙ ÙˆØ§Ù„Ø§Ø¹ØªÙ‚Ø§Ù„ ÙˆØ§Ù„ØªØ­Ù‚ÙŠÙ‚ ÙˆÙ…Ø§ ÙŠØ±Ø§ÙÙ‚Ù‡ Ù…Ù† ØªØ¹Ø°ÙŠØ¨ ÙˆØµÙ…ÙˆØ¯ ÙˆØªÙØ§Ø¹Ù„Ø§Øª ÙˆØµÙˆÙ„Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­Ø§ÙƒÙ…Ø© ÙˆØ§Ù„Ø­ÙŠØ§Ø© Ø§Ù„ÙØ±Ø¯ÙŠØ© ÙˆØ§Ù„Ø¬Ù…Ø§Ø¹ÙŠØ© ÙÙŠ Ø§Ù„Ø£Ø³Ø± ÙˆÙŠØ±Ø§ÙÙ‚Ù‡Ø§ Ø¥Ù„Ù‰ Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ­Ø±Ø± ÙˆÙ…Ø§ ÙŠØ¹Ù‚Ø¨Ù‡Ø§ Ù…Ù† Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ ÙˆØ§Ù„Ø§Ù†Ø¯Ù…Ø§Ø¬ ÙˆØ§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹Ù‡ . ÙƒÙ…Ø§ ØªÙ†Ø§ÙˆÙ„ Ø§Ù„ÙÙŠÙ„Ù… Ù…Ø´Ù‡Ø¯Ø§ Ù„Ø¬Ø¯Ø§Ø± Ø§Ù„ÙØµÙ„ Ø§Ù„Ø¹Ù†ØµØ±ÙŠ Ø§Ù„Ø°ÙŠ ÙŠÙ‡Ø¯Ø¯ Ø¨Ø¬Ø¹Ù„ Ø§Ù„ÙˆØ·Ù† Ø³Ø¬Ù†Ø§ ÙˆØ§Ù„Ø´Ø¹Ø¨ Ø³Ø¬Ù†Ø§Ø¡ ÙˆØ£Ø³Ø±Ù‰ Ø®Ù„Ù Ø£Ø³ÙˆØ§Ø± ÙˆØ£Ø³Ù„Ø§Ùƒ ÙˆØ¨ÙˆØ§Ø¨Ø§Øª ÙŠØªØ­ÙƒÙ… Ø¨Ù‡Ø§ Ø§Ù„Ø¬Ù†Ø¯ÙŠ Ø¨Ø¯Ù„ Ø§Ù„Ø³Ø¬Ø§Ù† . ÙŠØ°ÙƒØ± Ø£Ù† Ù„Ù„Ù…Ø®Ø±Ø¬Ø© Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ ÙˆØ§Ù„Ø£ÙÙ„Ø§Ù… Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© Ù…Ø¹ Ù…Ø®Ø±Ø¬Ø§Øª Ø£Ø®Ø±ÙŠØ§Øª Ù…Ù†Ù‡Ø§ ÙÙŠÙ„Ù… ( Ù†Ø³Ø§Ø¡ Ø¨Ø§Ù„Ø¬ÙˆØ§Ø± ) .</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ø²ÙˆØ§Ø¬ Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) Ø¬Ø§Ø¡ Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… Ø§Ù„Ù‰ Ø¨ÙŠØª Ø£Ø¨Ù‰ Ø¨ÙƒØ± Ø§Ù„ØµØ¯ÙŠÙ‚ ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡ ) ÙÙŠ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ù…Ø¹ Ø±Ø¬Ø§Ù„ ÙˆÙ†Ø³Ø§Ø¡ Ù…Ù† Ø§Ù„Ø£Ù†ØµØ§Ø± ÙˆÙƒØ§Ù†Øª Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶ÙŠ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) Ø¹Ù„Ù‰ Ø£Ø±Ø¬ÙˆØ­Ø© ØªØ±Ø¬Ø­ Ø¨ÙŠÙ† ÙØ±Ø¹ÙŠÙ† Ù…Ù† ÙØ±ÙˆØ¹ Ø§Ù„Ø´Ø¬Ø± ÙØ£Ù†Ø²Ù„ØªÙ‡Ø§ Ø£Ù…Ù‡Ø§ Ù…Ù† Ø§Ù„Ø£Ø±Ø¬ÙˆØ­Ø© Ø«Ù… Ø³ÙˆØª Ø´Ø¹Ø±Ù‡Ø§ ÙˆÙ…Ø³Ø­Øª ÙˆØ¬Ù‡Ù‡Ø§ Ø¨Ø§Ù„Ù…Ø§Ø¡ ÙˆØªØ±ÙƒØªÙ‡Ø§ Ø­ØªÙ‰ Ø³ÙƒÙ† Ù†ÙØ³Ù‡Ø§ Ù…Ù† Ø¬Ø±Ø§Ø¡ Ù„Ø¹Ø¨Ù‡Ø§ Ø«Ù… Ø¯Ø®Ù„Øª Ø¨Ù‡Ø§ ÙØ§Ø°Ø§ Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… Ø¬Ø§Ù„Ø³Ø§ Ø¹Ù„Ù‰ Ø³Ø±ÙŠØ± ÙˆÙ…Ø¹Ù‡ Ø±Ø¬Ø§Ù„ ÙˆÙ†Ø³Ø§Ø¡ Ù…Ù† Ø§Ù„Ø£Ù†ØµØ§Ø± Ø«Ù… Ù‚Ø§Ù„Øª Ø§Ù„Ø§Ù… Ù…Ø®Ø§Ø·Ø¨Ø© Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) : Ù‡Ø¤Ù„Ø§Ø¡ Ø£Ù‡Ù„Ùƒ ÙØ¨Ø§Ø±Ùƒ Ø§Ù„Ù„Ù‡ ÙØ¨Ø§Ø±Ùƒ Ø§Ù„Ù„Ù‡ ÙÙŠÙ‡Ù… ÙˆØ¨Ø§Ø±Ùƒ ÙÙŠÙƒ ! Ø«Ù… Ø£ÙƒÙ„ÙˆØ§ Ù…Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§ ÙÙ‰ Ø§Ù„Ø¨ÙŠØª Ù…Ù† Ø·Ø¹Ø§Ù… ÙˆÙ‚Ø¯Ù…ÙˆØ§ Ù„Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… Ù‚Ø¯Ø­Ø§ Ù…Ù† Ù„Ø¨Ù† ÙØ´Ø±Ø¨ Ù…Ù†Ù‡ ÙˆÙ†Ø§ÙˆÙ„Ù‡ Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) ÙØ®ÙØ¶Øª Ø±Ø£Ø³Ù‡Ø§ Ø­ÙŠØ§Ø¡ . . Ø«Ù… Ø£Ø®Ø°ØªÙ‡ Ù…Ù† Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… ÙˆØ´Ø±Ø¨Øª Ù…Ù†Ù‡ ØªØªØ°ÙƒØ± Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) ØªÙ„Ùƒ Ø§Ù„Ù„ÙŠÙ„Ø© ÙØªÙ‚ÙˆÙ„ : ( Ù…Ø§ Ù†Ø­Ø±Øª Ø¬Ø²ÙˆØ± . . ÙˆÙ„Ø§ Ø°Ø¨Ø­Øª Ø´Ø§Ø© ) Ø§Ù†ØªÙ‚Ù„Øª Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) Ø¥Ù„Ù‰ Ø¨ÙŠØª Ø§Ù„Ø²ÙˆØ¬ÙŠØ© ÙˆÙ‡Ùˆ Ø­Ø¬Ø±Ø© Ù…Ù† Ø§Ù„Ø·ÙˆØ¨ Ø§Ù„Ù„Ø¨Ù† ÙˆØ³Ù‚ÙØª Ø¨Ø³Ø¹Ù Ø§Ù„Ù†Ø®ÙŠÙ„ ÙˆØ£Ø³Ø¯Ù„Øª Ø¹Ù„Ù‰ Ø¨Ø§Ø¨Ù‡Ø§ Ø³ØªØ§Ø¦Ø± Ù…ØªØ®Ø°Ø© Ù…Ù† Ø§Ù„Ø´Ø¹Ø± ÙˆÙ‡Ø°Ø§ Ø§Ù„Ø¨Ø§Ø¨ ÙŠØ·Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø¬Ø¯ Ø¨Ø­ÙŠØ« ÙƒØ§Ù† ÙÙ‰ Ø§Ø³ØªØ·Ø§Ø¹Ø© Ø§Ù„Ø±Ø³ÙˆÙ„ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… Ø£Ù† ÙŠØ±Ù‰ Ø§Ù„ÙˆØ§Ù‚ÙÙŠÙ† ÙÙŠ Ø§Ù„ØµÙ„Ø§Ø© . Ù„Ù… ÙŠÙƒÙ† Ø£Ø«Ø§Ø« Ø¨ÙŠØª Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) Ù„ÙŠØ®ØªÙ„Ù ÙÙ‰ Ø¨Ø³Ø§Ø·ØªÙ‡ Ø¹Ù† Ø§Ù„Ø¨Ù†Ø§Ø¡ ÙˆÙ„ÙŠØ³ Ø£Ø¯Ù„ Ø¹Ù„Ù‰ Ø°Ù„Ùƒ Ù…Ù…Ø§ Ø¬Ø§Ø¡ Ø¹Ù„Ù‰ Ù„Ø³Ø§Ù† Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) ÙÙ‚Ø¯ Ø±ÙˆØª Ø£Ù† Ø¹Ù…Ø± Ø§Ø¨Ù† Ø§Ù„Ø®Ø·Ø§Ø¨ ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡ ) Ø¯Ø®Ù„ Ø¹Ù„Ù‰ Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… ÙˆÙƒØ§Ù† Ø±Ø§Ù‚Ø¯Ø§ ÙˆØªØ­Øª Ø±Ø£Ø³Ù‡ ÙˆØ³Ø§Ø¯Ø© Ù…Ù† Ø£Ø¯Ù… Ù…Ø­Ø´ÙˆØ© Ù„ÙŠÙØ§ ÙˆÙ„ÙŠØ³ Ø¨ÙŠÙ†Ù‡ ÙˆØ¨ÙŠÙ† Ø§Ù„Ø£Ø±Ø¶ Ø¥Ù„Ø§ Ø§Ù„Ø­ØµÙŠØ± ÙÙ„Ù…Ø§ Ø±Ø£Ù‰ Ø¹Ù…Ø± ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡ ) Ø°Ù„Ùƒ Ø°Ø±ÙØª Ø¹ÙŠÙ†Ø§Ù‡ Ø¨Ø§Ù„Ø¯Ù…ÙˆØ¹ . Ù‚Ø§Ù„ Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… : ( Ù…Ø§ ÙŠØ¨ÙƒÙŠÙƒ ÙŠØ§Ø¹Ù…Ø± ) . Ù‚Ø§Ù„ Ø¹Ù…Ø± ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡ ) : ÙƒØ³Ø±Ù‰ ÙˆÙ‚ÙŠØµØ± Ø¹Ø¯ÙˆØ§ Ø§Ù„Ù„Ù‡ ÙŠÙØ±Ø´Ø§Ù† Ø§Ù„Ø¯ÙŠØ¨Ø§Ø¬ ÙˆØ§Ù„Ø­Ø±ÙŠØ± ÙˆØ£Ù†Øª Ù†Ø¨ÙŠÙ‡ ÙˆØµÙÙŠÙ‡ ÙˆÙ„ÙŠØ³ Ø¨ÙŠÙ†Ùƒ ÙˆØ¨ÙŠÙ† Ø§Ù„Ø£Ø±Ø¶ Ø¥Ù„Ø§ Ø§Ù„Ø­ØµÙŠØ± ÙˆÙˆØ³Ø§Ø¯Ø© Ù…Ø­Ø´ÙˆØ© Ù„ÙŠÙØ§ . ÙÙ‚Ø§Ù„ Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… : Ø£ÙˆÙ„Ø¦Ùƒ Ø¹Ø¬Ù„Øª Ù„Ù‡Ù… Ø·ÙŠØ¨Ø§ØªÙ‡Ù… ) . ÙˆØªÙ‚ÙˆÙ„ Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶ÙŠ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) : ( Ù„Ù… ÙŠÙƒÙ† Ù„Ø¯ÙŠÙ†Ø§ Ø¥Ù„Ø§ ÙØ±Ø§Ø´ ÙˆØ§Ø­Ø¯ ÙÙ‰ Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ø£Ù…Ø± Ø«Ù… Ø±Ø²Ù‚Ù†Ø§ ÙØ±Ø§Ø´Ø§ Ø¢Ø®Ø± ) . ÙˆÙ„Ù‚Ø¯ Ø£Ø¹Ø·Øª Ø¥Ø­Ø¯Ù‰ Ø§Ù„ØµØ­Ø§Ø¨ÙŠØ§Øª ÙØ±Ø§Ø´Ø§ ÙˆØ«ÙŠØ±Ø§ Ù„Ù„Ø³ÙŠØ¯Ø© Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) ÙˆØ£Ø±Ø³Ù„ØªÙ‡ Ø¥Ù„ÙŠÙ‡Ø§ ÙØ£Ù…Ø±Ù‡Ø§ Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… Ø£Ù† ØªØ±Ø¯Ù‡ Ù„ØµØ§Ø­Ø¨ØªÙ‡Ø§ . ÙˆÙ„Ù… ÙŠÙƒÙ† Ø·Ø¹Ø§Ù…Ù‡Ù…Ø§ Ø¨Ø£Ù‚Ù„ Ø¨Ø³Ø§Ø·Ø© Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙŠØª ÙˆØ§Ù„Ø£Ø«Ø§Ø« Ø¨Ù„ Ø¥Ù† Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) ØªÙ‚ÙˆÙ„ : ( ÙƒØ§Ù† ÙŠØ£ØªÙ‰ Ø¢Ù„ Ù…Ø­Ù…Ø¯ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… Ø§Ù„Ø´Ù‡Ø± Ù…Ø§ ÙŠØ®ØªØ¨Ø²ÙˆÙ† Ø®Ø¨Ø²Ø§ ÙˆÙ„Ø§ ÙŠØ·Ø¨Ø®ÙˆÙ† Ù‚Ø¯Ø±Ø§ ) . Ù„Ù‚Ø¯ Ø£Ù…Ø¶Øª Ø¹Ø§Ø¦Ø´Ø© ( Ø±Ø¶Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ø§ ) Ø­ÙŠØ§ØªÙ‡Ø§ ÙÙ‰ Ø§Ù„Ø¨ÙŠØª Ø§Ù„Ø°Ù‰ ØªØ²ÙˆØ¬Øª ÙÙŠÙ‡ ÙˆÙ„Ù… ØªØºÙŠØ±Ù‡ ÙˆÙ„Ù… ØªØ³ØªØ¨Ø¯Ù„ Ø·ÙŠÙ„Ø© Ø­ÙŠØ§ØªÙ‡Ø§ Ø¨Ù‡ ØºÙŠØ±Ù‡ .</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["show_random_elements(datasets['train'])"]},{"cell_type":"markdown","metadata":{},"source":["## 4- Toknize and process the Dataset\n","* Initializes the tokenizer from the pre-trained \"aragpt2-base\" model, then tokenizes the entire dataset in parallel using four processes, while removing the original \"text\" column.\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:50:00.918037Z","iopub.status.busy":"2024-10-21T20:50:00.917664Z","iopub.status.idle":"2024-10-21T20:50:31.535249Z","shell.execute_reply":"2024-10-21T20:50:31.534202Z","shell.execute_reply.started":"2024-10-21T20:50:00.917994Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66f326ac16164798a19526e318330371","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3275e470dfa64b10bc097b3d270715ac","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68ae34029c264b8889995517d87be9df","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.50M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"269bd45221864ae3b95a00366da9e094","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/4.52M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"924ebc6156bf4c0cbd1615449d32bc2d","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/16383 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"142eb9340cf94f0e80ef8fdff0798c11","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/1821 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_checkpoint = \"aubmindlab/aragpt2-base\"  \n","\n","# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n","\n","# Tokenization function\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"])\n","\n","# Tokenize the datasets\n","tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:50:31.537107Z","iopub.status.busy":"2024-10-21T20:50:31.536764Z","iopub.status.idle":"2024-10-21T20:50:31.544657Z","shell.execute_reply":"2024-10-21T20:50:31.543730Z","shell.execute_reply.started":"2024-10-21T20:50:31.537071Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': [21993, 4213, 10075, 537, 12273], 'attention_mask': [1, 1, 1, 1, 1]}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer(\"Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªÙ‡\")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:50:31.546403Z","iopub.status.busy":"2024-10-21T20:50:31.546117Z","iopub.status.idle":"2024-10-21T20:50:31.557326Z","shell.execute_reply":"2024-10-21T20:50:31.556468Z","shell.execute_reply.started":"2024-10-21T20:50:31.546371Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [941, 453, 283, 291, 300, 288, 300, 287, 383, 2076, 5329, 3137, 4998, 3479, 2387, 12532, 262, 708, 10784, 424, 19968, 949, 5757, 36406, 20556, 26035, 355, 13688, 737, 391, 6653, 305, 41019, 305, 5331, 1808, 308, 8722, 3699, 3810, 1836, 15578, 2782, 51788, 8301, 18322, 305, 3849, 1048, 708, 10784, 45305, 36406, 945, 32242, 8593, 1739, 5114, 802, 2945, 3387, 1817, 308, 8593, 468, 10787, 8033, 305, 2945, 3804, 15104, 2581, 52727, 305, 23610, 300, 1943, 2161, 355, 31433, 3478, 8139, 5458, 5047, 424, 9133, 483, 39078, 8339, 21008, 2503, 60696, 2610, 4846, 1576, 2719, 8301, 10668, 15833, 4085, 14014, 6394, 30665, 13720, 416, 26652, 843, 995, 5140, 7192, 31060, 410, 651, 2610, 41010, 332, 809, 5381, 5605, 2928, 618, 424, 3137, 4998, 5360, 618, 3849, 15018, 355, 1011, 16166, 468, 27373, 1048, 7192, 877, 15018, 32345, 1780, 2610, 25577, 10342, 34643, 13720, 416, 843, 6019, 300, 5140, 4583, 483, 2527, 17806, 1446, 22193, 8488, 1824, 1576, 4448, 13688, 565, 522, 5624, 365, 1230, 2346, 3552, 305, 7015, 2732, 56124, 474, 41770, 364, 4448, 13688, 483, 12784, 308, 1792, 3615, 2542, 4448, 394, 499, 1873, 36954, 364, 57762, 618, 30536, 6313, 3804, 305, 13525, 522, 394, 35168, 2116, 11265, 300, 1943, 4126, 416, 1088, 416, 1206, 4111, 15324, 416, 355, 4833, 6864, 7189, 305, 7015, 2732, 21261, 19665, 618, 6478, 61995, 308, 3354, 1813, 5047, 424, 52032, 3920, 622, 30886, 1155, 702, 2928, 618, 1589, 15435, 54053, 305, 7015, 1471, 16085, 61953, 9401, 4979, 1616, 15435, 52991, 10416, 416, 2517, 11237, 63039, 7072, 1310, 2253, 300, 308, 8694, 2076, 4795, 3137, 4998, 3660, 1648, 31132, 273, 364, 3137, 2960, 2008, 4851, 6028, 5335, 6122, 618, 8593, 1739, 18734, 416, 305, 10787, 332, 33111, 2945, 3803, 1576, 2719, 8301, 872, 3987, 1526, 15894, 63404, 1180, 300, 4051, 5329, 13688, 19266, 7687, 517, 20424, 2619, 13660, 30006, 8640, 2731, 1087, 3518, 39020, 7649, 4998, 4448, 2346, 59883, 13108, 4851, 2368, 522, 15041, 2116, 2640, 4583, 1943, 17112, 416, 11970, 2214, 305, 1137, 2481, 13914, 1230, 1457, 305, 7906, 14780, 416, 3569, 2392, 22319, 63039, 7072, 1310, 2253, 47329, 737, 11261, 1632, 17466, 22818, 796, 1684, 618, 53148, 11261, 474, 16877, 7943, 18959, 1424, 57349, 305, 15607, 945, 482, 7347, 1247, 305, 13660, 19203, 43455, 618, 3849, 30921, 355, 8857, 41139, 543, 3699, 5047, 424, 7943, 10500, 2438, 2368, 46186, 9485, 308, 578, 2408, 25480, 424, 1310, 7849, 3803, 54668, 300], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"]}],"source":["print(tokenized_datasets['train'][0])"]},{"cell_type":"markdown","metadata":{},"source":["* Takes the tokenized text data and splits it into smaller chunks, each with a fixed size of 128 tokens. It groups the texts together, ensures the total length is a multiple of the block size. Then, it applies this splitting process to the entire dataset using four parallel processes, making the data ready for processes fixed-length text chunks."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:50:31.558617Z","iopub.status.busy":"2024-10-21T20:50:31.558316Z","iopub.status.idle":"2024-10-21T20:50:31.567416Z","shell.execute_reply":"2024-10-21T20:50:31.566619Z","shell.execute_reply.started":"2024-10-21T20:50:31.558585Z"},"trusted":true},"outputs":[],"source":["block_size = 128  \n","\n","def group_texts(examples):\n","    # Concatenate all texts.\n","    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n","    total_length = len(concatenated_examples[list(examples.keys())[0]])\n","    # We drop the small remainder\n","    total_length = (total_length // block_size) * block_size\n","    # Split by chunks of max_len.\n","    result = {\n","        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n","        for k, t in concatenated_examples.items()\n","    }\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:51:18.607845Z","iopub.status.busy":"2024-10-21T20:51:18.606848Z","iopub.status.idle":"2024-10-21T20:51:52.531076Z","shell.execute_reply":"2024-10-21T20:51:52.530149Z","shell.execute_reply.started":"2024-10-21T20:51:18.607803Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bfebdf34aeb7481ea27acd76002bd8c2","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/16383 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22c8aeddf9cb41408a789b26497a36e3","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/1821 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["lm_datasets = tokenized_datasets.map(\n","    group_texts,\n","    batched=True,\n","    num_proc=4,\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:51:52.534004Z","iopub.status.busy":"2024-10-21T20:51:52.533470Z","iopub.status.idle":"2024-10-21T20:51:52.541308Z","shell.execute_reply":"2024-10-21T20:51:52.540297Z","shell.execute_reply.started":"2024-10-21T20:51:52.533951Z"},"trusted":true},"outputs":[{"data":{"text/plain":["GPT2TokenizerFast(name_or_path='aubmindlab/aragpt2-base', vocab_size=64000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n","\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t2: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t3: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:51:52.542714Z","iopub.status.busy":"2024-10-21T20:51:52.542424Z","iopub.status.idle":"2024-10-21T20:51:52.554435Z","shell.execute_reply":"2024-10-21T20:51:52.553566Z","shell.execute_reply.started":"2024-10-21T20:51:52.542675Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 75418\n","})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["lm_datasets['train']"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:51:52.556530Z","iopub.status.busy":"2024-10-21T20:51:52.556243Z","iopub.status.idle":"2024-10-21T20:51:52.567734Z","shell.execute_reply":"2024-10-21T20:51:52.566856Z","shell.execute_reply.started":"2024-10-21T20:51:52.556499Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'ØµÙØ§Ù‚Ø³ Ø£ . Ù . Ø¨ : Ø£ÙƒØ¯ Ù…Ø¯Ø±Ø¨ Ø§Ù„Ù…Ù†ØªØ®Ø¨ Ø§Ù„Ù…ØºØ±Ø¨ÙŠ Ù„ÙƒØ±Ø© Ø§Ù„Ù‚Ø¯Ù… Ø¨Ø§Ø¯Ùˆ Ø§Ù„Ø²Ø§ÙƒÙŠ Ø§Ù† Ù…Ù†ØªØ®Ø¨Ù‡ Ø­Ù‚Ù‚ Ø§Ù„Ø§Ù‡Ù… Ø¨ÙÙˆØ²Ù‡ Ø§Ù„Ø¹Ø±ÙŠØ¶ Ø¹Ù„Ù‰ Ø¨Ù†ÙŠÙ† 4 - ØµÙØ± ÙÙŠ ØµÙØ§Ù‚Ø³ ÙÙŠ Ø§Ù„Ø¬ÙˆÙ„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ù…Ù†Ø§ÙØ³Ø§Øª Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø© Ø¶Ù…Ù† Ù†Ù‡Ø§Ø¦ÙŠØ§Øª ÙƒØ£Ø³ Ø§Ù…Ù… Ø§ÙØ±ÙŠÙ‚ÙŠØ§ Ø§Ù„Ù…Ù‚Ø§Ù…Ø© ÙÙŠ ØªÙˆÙ†Ø³ ÙˆÙ‚Ø§Ù„ Ø§Ù„Ø²Ø§ÙƒÙŠ Ø­Ù‚Ù‚Ù†Ø§ Ø§Ù„Ø§Ù‡Ù… ÙˆÙ‡Ùˆ Ø§Ù†ØªØ²Ø§Ø¹ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø«Ù„Ø§Ø« Ù‚Ù„Øª Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø© Ø§Ù†Ù‡Ø§ Ø£Ù‡Ù… Ù…Ù† Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙŠ ÙƒØ³Ø¨Ù†Ø§Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø© Ø§Ù„Ø§ÙˆÙ„Ù‰ ÙˆØ§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ù†Ø¬Ø­Ù†Ø§ ÙÙŠ Ù‡Ø¯ÙÙ†Ø§ . ÙˆØ£Ø¶Ø§Ù Ù†Ø­Ù† Ø¹Ù„Ù‰ Ù…Ø´Ø§Ø±Ù Ø§Ù„Ø¯ÙˆØ± Ø±Ø¨Ø¹ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨ÙŠØ¯ Ø§Ù† Ø§Ù„Ø§Ù…ÙˆØ± Ù„Ù… ØªØ­Ø³Ù… Ø¨ØµÙØ© Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ø§Ù† Ø§Ù…Ø§Ù…Ù†Ø§ Ù…Ø¨Ø§Ø±Ø§Ø© Ù‚ÙˆÙŠØ© Ø¶Ø¯ Ø¬Ù†ÙˆØ¨ Ø§ÙØ±ÙŠÙ‚ÙŠØ§ Ø³Ù†ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§ Ø¨Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù„ØªØ£ÙƒÙŠØ¯ Ù…Ø´ÙˆØ§Ø±Ù†Ø§ Ø§Ù„Ù†Ø§Ø¬Ø­ Ø­ØªÙ‰ Ø§Ù„Ø§Ù† ÙˆØªØ§Ø¨Ø¹ Ø§Ù†Ù†Ø§ Ù†ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ ÙƒÙ„ Ù…Ø¨Ø§Ø±Ø§Ø© Ø¨Ø¸Ø±ÙˆÙÙ‡Ø§ ÙˆØ­Ø³Ø§Ø³ÙŠØªÙ‡Ø§ Ù…Ø´ÙŠØ±Ø§ Ø§Ù„Ù‰ Ø§Ù† Ø§Ù„Ù…Ù†ØªØ®Ø¨ Ø§Ù„Ù…ØºØ±Ø¨ÙŠ Ø­Ø¶Ø± Ø§Ù„Ù‰ ØªÙˆÙ†Ø³ Ù„Ù„ÙÙˆØ²'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(lm_datasets[\"train\"][0][\"input_ids\"])"]},{"cell_type":"markdown","metadata":{},"source":["* Sets the tokenizer to use the \"end of sentence\" token as the padding token, and then creates a data helper (collator) that prepares batches of text for training."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:51:52.569664Z","iopub.status.busy":"2024-10-21T20:51:52.568869Z","iopub.status.idle":"2024-10-21T20:51:52.575624Z","shell.execute_reply":"2024-10-21T20:51:52.574715Z","shell.execute_reply.started":"2024-10-21T20:51:52.569618Z"},"trusted":true},"outputs":[],"source":["tokenizer.pad_token = tokenizer.eos_token\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:51:52.577801Z","iopub.status.busy":"2024-10-21T20:51:52.576921Z","iopub.status.idle":"2024-10-21T20:51:52.584872Z","shell.execute_reply":"2024-10-21T20:51:52.584129Z","shell.execute_reply.started":"2024-10-21T20:51:52.577766Z"},"trusted":true},"outputs":[],"source":["model_name = model_checkpoint.split(\"/\")[-1]\n"]},{"cell_type":"markdown","metadata":{},"source":["## 5- Train the dataset\n","* loads a pre-trained CLM, sets up training arguments, enables gradient checkpointing to save memory, and initializes a Trainer to manage the training and evaluation process using the specified datasets."]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:52:14.748423Z","iopub.status.busy":"2024-10-21T20:52:14.747495Z","iopub.status.idle":"2024-10-21T20:52:21.279795Z","shell.execute_reply":"2024-10-21T20:52:21.278803Z","shell.execute_reply.started":"2024-10-21T20:52:14.748381Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34ecac35a7364e2daa9e8d1e7b3126a0","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/553M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"]}],"source":["# Load the model\n","model = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n","\n","# Set training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./ArabicGenrationV3\",# Location to save model outputs\n","    num_train_epochs=3,             # Train for 5 epochs\n","    evaluation_strategy=\"epoch\",    # Evaluate after each epoch\n","    learning_rate=2e-5,             # Set learning rate\n","    weight_decay=0.01,              # Apply weight decay for regularization\n","    push_to_hub=False,               # Push model to Hugging Face Hub\n","    logging_dir=\"./logs\",           # Save logs in this directory\n","    logging_steps=5,                # Log training progress every 5 steps\n","    fp16=True,                      # Use mixed precision for faster training\n","    gradient_accumulation_steps=8,  # Accumulate gradients over 8 steps\n","    per_device_train_batch_size=4,  # Reduce the batch size\n","    per_device_eval_batch_size=4,   # Reduce the evaluation batch size \n","    save_strategy=\"epoch\",            # Save checkpoints less frequently, only once per epoch\n","    save_total_limit=2,               # Only keep the last 2 checkpoints to avoid overuse of disk space\n","    load_best_model_at_end=True,      # Load the best model at the end of training based on evaluation\n",")\n","model.gradient_checkpointing_enable()\n","\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,                           # The model to be trained.\n","    args=training_args,                    # Training parameterss.\n","    train_dataset=lm_datasets[\"train\"],    # The dataset used for training.\n","    eval_dataset=lm_datasets[\"test\"]       # The dataset used for evaluation .\n",")\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T20:52:21.282152Z","iopub.status.busy":"2024-10-21T20:52:21.281543Z","iopub.status.idle":"2024-10-21T22:47:26.624186Z","shell.execute_reply":"2024-10-21T22:47:26.623324Z","shell.execute_reply.started":"2024-10-21T20:52:21.282103Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b28572d6f5914012ab74e3227c405c3e","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113128522222522, max=1.0â€¦"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241021_205315-thw6n4th</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/xfoxxe-/huggingface/runs/thw6n4th' target=\"_blank\">./ArabicGenrationV3</a></strong> to <a href='https://wandb.ai/xfoxxe-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/xfoxxe-/huggingface' target=\"_blank\">https://wandb.ai/xfoxxe-/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/xfoxxe-/huggingface/runs/thw6n4th' target=\"_blank\">https://wandb.ai/xfoxxe-/huggingface/runs/thw6n4th</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='7068' max='7068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7068/7068 1:54:06, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>4.806100</td>\n","      <td>4.195044</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>4.787500</td>\n","      <td>4.111362</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>4.761500</td>\n","      <td>4.085032</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n","  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"]},{"data":{"text/plain":["TrainOutput(global_step=7068, training_loss=4.879864146632533, metrics={'train_runtime': 6904.5616, 'train_samples_per_second': 32.769, 'train_steps_per_second': 1.024, 'total_flos': 1.4774235365376e+16, 'train_loss': 4.879864146632533, 'epoch': 2.9988862370723943})"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Train the model\n","trainer.train()\n"]},{"cell_type":"markdown","metadata":{},"source":["* Save the results model in Hugging Face Hub"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T23:00:16.758866Z","iopub.status.busy":"2024-10-21T23:00:16.758432Z","iopub.status.idle":"2024-10-21T23:00:16.768416Z","shell.execute_reply":"2024-10-21T23:00:16.767513Z","shell.execute_reply.started":"2024-10-21T23:00:16.758828Z"},"trusted":true},"outputs":[{"data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(64000, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2SdpaAttention(\n","          (c_attn): Conv1D(nf=2304, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=768)\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D(nf=3072, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=3072)\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=64000, bias=False)\n",")"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T23:00:28.320206Z","iopub.status.busy":"2024-10-21T23:00:28.319804Z","iopub.status.idle":"2024-10-21T23:00:58.723416Z","shell.execute_reply":"2024-10-21T23:00:58.722558Z","shell.execute_reply.started":"2024-10-21T23:00:28.320165Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3e5ddba0aff4466a50336340bad8e07","version_major":2,"version_minor":0},"text/plain":["training_args.bin:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"611e3134e5af479a9e06e66a18ce4317","version_major":2,"version_minor":0},"text/plain":["Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"158b0bca16d34a648928bacf47126e6f","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/540M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/xfoxxe/ArabicGenrationV3/commit/56c099ba0f028367074d353cb5368568b885fd5d', commit_message='End of training', commit_description='', oid='56c099ba0f028367074d353cb5368568b885fd5d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/xfoxxe/ArabicGenrationV3', endpoint='https://huggingface.co', repo_type='model', repo_id='xfoxxe/ArabicGenrationV3'), pr_revision=None, pr_num=None)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Push the trained model to HF\n","trainer.push_to_hub()\n"]},{"cell_type":"markdown","metadata":{},"source":["## 6- Evaluation \n","* evaluates the model: calculates the perplexity (a measure of how well the model predicts the text), and prints the result.\n","\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T23:01:55.326999Z","iopub.status.busy":"2024-10-21T23:01:55.326574Z","iopub.status.idle":"2024-10-21T23:03:01.798339Z","shell.execute_reply":"2024-10-21T23:03:01.797287Z","shell.execute_reply.started":"2024-10-21T23:01:55.326960Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2129' max='2129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2129/2129 01:06]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 4.085031509399414, 'eval_runtime': 66.4571, 'eval_samples_per_second': 128.098, 'eval_steps_per_second': 32.036, 'epoch': 2.9988862370723943}\n","Perplexity: 59.44\n"]}],"source":["\n","# Evaluate the model\n","eval_results = trainer.evaluate()\n","print(eval_results)\n","import math\n","print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## 7- Prediction example"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T23:03:49.932865Z","iopub.status.busy":"2024-10-21T23:03:49.932453Z","iopub.status.idle":"2024-10-21T23:03:51.501083Z","shell.execute_reply":"2024-10-21T23:03:51.500155Z","shell.execute_reply.started":"2024-10-21T23:03:49.932825Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["Generated text: Ø¹Ø§ØµÙ…Ø© Ø³Ù„Ø·Ù†Ø© Ø¹Ù…Ø§Ù† Ù‡ÙŠ Ù…Ø³Ù‚Ø· Ø§Ù„ØªÙŠ Ø§Ø­ØªØ¶Ù†Øª Ø§Ù„Ù…Ù„ØªÙ‚Ù‰ Ø§Ù„Ø³Ù†ÙˆÙŠ Ø§Ù„Ø±Ø§Ø¨Ø¹ Ù„Ù„ÙƒØªØ§Ø¨ ÙˆØ§Ù„Ø°ÙŠ Ø¹Ù‚Ø¯ ØªØ­Øª Ø´Ø¹Ø§Ø± ( Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙÙŠ Ø¹Ù…Ø§Ù† ) . ÙˆÙ‚Ø¯ Ø±Ø¹Ù‰ Ø­ÙÙ„ Ø§Ù„Ø®ØªØ§Ù… Ø³Ø¹Ø§Ø¯Ø© Ø§Ù„Ø´ÙŠØ® Ø³Ø§Ù„Ù… Ø¨Ù† Ø³Ø§Ù„Ù… Ø§Ù„Ø±Ø§Ø´Ø¯ÙŠ ÙˆÙƒÙŠÙ„ ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¨Ù„Ø¯ÙŠØ§Øª Ø§Ù„Ø§Ù‚Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„Ø¨ÙŠØ¦Ø© ÙˆÙ…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…ÙŠØ§Ù‡ ÙˆØ¨Ø­Ø¶ÙˆØ± Ø¹Ø¯Ø¯ Ù…Ù† Ø§ØµØ­Ø§Ø¨ Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© Ø§Ø¹Ø¶Ø§Ø¡ Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¯ÙˆÙ„Ø© ÙˆØ±Ø¤Ø³Ø§Ø¡ Ù…Ø¬Ø§Ù„Ø³ Ø§Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø¬Ø§Ù…Ø¹Ø§Øª ÙˆØ§Ù„ÙƒÙ„ÙŠØ§Øª ÙˆÙ…Ø¯ÙŠØ±ÙŠ Ø§Ù„Ø¹Ù…ÙˆÙ… ÙˆÙ…Ø¯ÙŠØ±ÙŠ Ø§Ù„Ø¯ÙˆØ§Ø¦Ø± Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ© ÙˆØ§Ù„Ø®Ø§ØµØ© ÙˆØ¬Ù…Ø¹ ØºÙÙŠØ± Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ† . ÙˆØ®Ù„Ø§Ù„ Ø­ÙÙ„ Ø§Ù„Ø§ÙØªØªØ§Ø­ Ø£Ù„Ù‚Ù‰ Ø³Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¯ÙƒØªÙˆØ± Ø¹Ù„ÙŠ Ø¨Ù† Ø³Ù„ÙŠÙ…Ø§Ù† Ø§Ù„Ù…Ø¹Ù…Ø±ÙŠ Ù…Ø¯ÙŠØ± Ø¹Ø§Ù… Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ© ÙƒÙ„Ù…Ø© Ù‚Ø§Ù„ ÙÙŠÙ‡Ø§ : Ø§Ù† Ø§Ù„Ù…Ø¤ØªÙ…Ø± Ø§Ù„Ø°ÙŠ Ù†Ø¸Ù…ØªÙ‡ ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØªÙ†Ù…ÙŠØ© Ø§Ù„Ø¥Ø¬ØªÙ…Ø§Ø¹ÙŠØ© Ù‡Ùˆ Ù†ØªØ§Ø¬ Ø·Ø¨ÙŠØ¹ÙŠ Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù… ÙˆØ§Ù„Ø¹Ù†Ø§ÙŠØ© Ø§Ù„Ø®Ø§ØµØ© Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø¤Ø³Ø³Ø§Øª Ø§Ù„Ù…Ø¹Ù†ÙŠØ©\n"]}],"source":["import torch  # <-- Make sure to import torch\n","\n","# Check if GPU (CUDA) is available and set the device accordingly\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)  # Move the model to the correct device\n","\n","# Example: Generate text after training\n","def generate_text(prompt, max_length=50):\n","    # Tokenize the input prompt\n","    inputs = tokenizer(prompt, return_tensors=\"pt\")\n","    \n","    # Generate text\n","    output = model.generate(\n","        inputs[\"input_ids\"].to(device),\n","        attention_mask=inputs[\"attention_mask\"].to(device),\n","        max_length=max_length,\n","        num_return_sequences=1,\n","        no_repeat_ngram_size=2,  # Avoid repeating n-grams\n","        do_sample=True,  # Random sampling for more varied text\n","        top_k=50,  # Limit sampling pool\n","        top_p=0.95,  # Nucleus sampling\n","        temperature=0.7  # Control randomness\n","    )\n","    \n","    # Decode and print the generated text\n","    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","    print(f\"Generated text: {generated_text}\")\n","\n","# Example usage\n","prompt = \"Ø¹Ø§ØµÙ…Ø© Ø³Ù„Ø·Ù†Ø© Ø¹Ù…Ø§Ù† Ù‡ÙŠ \"\n","generate_text(prompt, max_length=100)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5915358,"sourceId":9678255,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
